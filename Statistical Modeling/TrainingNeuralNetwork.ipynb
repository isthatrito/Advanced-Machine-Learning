{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network\n",
    "*Curtis Miller*\n",
    "\n",
    "In this notebook I demonstrate how to train the neural network known as the **multilayer perceptron (MLP)**. We will use a MLP to classify the iris dataset and also a dataset of handwritten digits, in order to detect different characters.\n",
    "\n",
    "Neural networks have a lot of parameters to set when training. These include:\n",
    "\n",
    "* How many hidden layers to have\n",
    "* How many neurons to include in each layer\n",
    "* The activation functions of neurons in the hidden layers\n",
    "* Value of the regularization term to control overfitting (referred to as $\\alpha$)\n",
    "\n",
    "Issues when training a neural network are also accute. These are choices related to the actual optimization algorithm that estimates the parameters used for prediction. For neural networks this fitting process is very involved.\n",
    "\n",
    "MLPs are online algorithms just like perceptrons. This is especially advantageous for training on large datasets that don't necessarily fit into data. Additionally, MLPs are *not* linear classifiers/regressors. This suggests that MLPs are most popular for learning problems that require fitting data that isn't linearly separable.\n",
    "\n",
    "MLPs can be used for classification and regression. This notebook focuses on classification.\n",
    "\n",
    "First, lets load in the datasets we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the iris dataset\n",
    "iris_obj = load_iris()\n",
    "iris_data_train, iris_data_test, species_train, species_test = train_test_split(iris_obj.data, iris_obj.target)\n",
    "\n",
    "# Next, the digits dataset\n",
    "digits_obj = load_digits()\n",
    "print(digits_obj.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_obj.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data_train, digits_data_test, number_train, number_test = train_test_split(digits_obj.data, digits_obj.target)\n",
    "number_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data_train[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data_train[0, :].reshape((8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(digits_data_train[0, :].reshape((8, 8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a MLP to the Iris Data\n",
    "\n",
    "MLP models are implemented via the `MLPClassifier` object in **scikit-learn**. The MLP classifier I train:\n",
    "\n",
    "* Has one hidden layer with 20 neurons\n",
    "* Uses the logistic activation function for the hidden layers\n",
    "* Uses a regularization parameter of $\\alpha = 1$\n",
    "\n",
    "I demonstrate its use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_iris = MLPClassifier(hidden_layer_sizes=(20,),    # A tuple with the number of neurons for each hidden layer\n",
    "                         activation='logistic',         # Which activation function to use\n",
    "                         alpha=1,                       # Regularization parameter\n",
    "                         max_iter=1000)                 # Maximum number of iterations taken by the solver\n",
    "mlp_iris = mlp_iris.fit(iris_data_train, species_train)\n",
    "mlp_iris.predict(iris_data_train[:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_pred_train = mlp_iris.predict(iris_data_train)\n",
    "accuracy_score(species_pred_train, species_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_pred_test = mlp_iris.predict(iris_data_test)\n",
    "accuracy_score(species_pred_test, species_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier has extremely high accuracy for this dataset.\n",
    "\n",
    "## Fitting a MLP to the Digits Dataset\n",
    "\n",
    "Let's now see how the MLP classifier performs for the digits dataset. Again there is only one hidden layer, this one with 50 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_digits = MLPClassifier(hidden_layer_sizes=(50,),\n",
    "                           activation='logistic',\n",
    "                           alpha=1)\n",
    "mlp_digits = mlp_digits.fit(digits_data_train, number_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_digits.predict(digits_data_train[[0], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_pred_train = mlp_digits.predict(digits_data_train)\n",
    "accuracy_score(number_pred_train, number_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_pred_test = mlp_digits.predict(digits_data_test)\n",
    "accuracy_score(number_pred_test, number_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier shines in these nonlinear contexts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
