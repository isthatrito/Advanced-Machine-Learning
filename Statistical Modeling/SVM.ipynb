{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Support Vector Machines (SVM) for Classification and Detection\n",
    "*Curtis Miller*\n",
    "\n",
    "**Support vector machines (SVMs)** are linear classifiers. An SVM can be understood as a hyperplane (think: line) such that on one side of the plane consists of data only belonging to one class (ideally) while on the other side all instances of the other class exist. Prediction amounts to determining on which side of the line a data point lies.\n",
    "\n",
    "Training an SVM involves finding a hyperplane that best separates data from different classes and trying to maximize the margin between the plane and the nearest data points from two different classes. By doing this SVMs tend to generalize well from training data to future data; they are not known to be prone to overfitting.\n",
    "\n",
    "A hyperparameter common to all SVMs is a parameter $C$ known as the error penalty parameter. Smaller $C$ tends to combat overfitting.\n",
    "\n",
    "SVMs can be trained using the `SVC` object provided in **scikit-learn**\n",
    "\n",
    "## Kernel Methods\n",
    "\n",
    "The linearity assumption seems restrictive. Analysts overcome it by choosing a **kernel**, a mathematical function that alters the feature space a SVM is trained on. Choosing different kernels allows the boundary between classes to take different shapes, which may lead to better predictions.\n",
    "\n",
    "Again, we can consider choice of kernel as a hyperparameter to optimize. However, we may also use **domain knowledge** (our understanding of the phenomenon being learned) to pick a kernel.\n",
    "\n",
    "Let's load in the *Titanic* dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(110717)\n",
    "\n",
    "titanic = pd.read_csv(\"titanic.csv\")\n",
    "titanic.replace({'Sex': {'male': 0, 'female': 1}}, inplace=True)\n",
    "titanic.drop(\"Name\", axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we would be wise to handle passenger class with more care. While written as numbers this is actually a categorical or ordinal variable; the actual numbers don't matter. We should have binary variables, one for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(titanic.Pclass).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.join(pd.get_dummies(titanic.Pclass, prefix='Pclass')).drop(\"Pclass\", axis=1)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train, titanic_test = train_test_split(titanic)\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM\n",
    "\n",
    "We can train a SVM like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVC(C=1.0,              # Penalty parameter C\n",
    "           kernel='linear')    # Using a linear kernel\n",
    "svm1.fit(X=titanic_train.drop(\"Survived\", axis=1), y=titanic_train.Survived)\n",
    "\n",
    "svm1.predict([[0, 26, 0, 0, 30, 0, 1, 0]])    # Predicting whether a 26 year old male without family aboard in second\n",
    "                                              # class who paid $30 fare would survive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the kernel and $C$ could be done with cross-validation, but I will not demonstrate this (it would take too long for this video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(titanic_train.Survived, svm1.predict(titanic_train.drop(\"Survived\", axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM does reasonably well on the training data. Let's see how it does on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_test_predict = svm1.predict(titanic_test.drop(\"Survived\", axis=1))\n",
    "print(classification_report(titanic_test.Survived, survived_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on test data is slightly worse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
