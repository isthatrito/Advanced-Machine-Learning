{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# we use the mnist digits to demonstrate image classifaction using a convolutional neural network\n",
    "# use the supplied utility to load MNIST data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11a7d3ef0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwRE8IGA/g8LkpS7I5eATAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110927da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "io.imshow(np.reshape(mnist.train.images[0],(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(dimensions,stddev):\n",
    "  return tf.Variable(tf.truncated_normal(dimensions, stddev=stddev))\n",
    "\n",
    "def bias_variable(dimensions,constant):\n",
    "  return tf.Variable(tf.constant(constant, shape=dimensions))\n",
    "\n",
    "def two_dimensional_convolutional_layer(x, W, strides, padding):\n",
    "  return tf.nn.conv2d(x, W, strides=strides, padding=padding)\n",
    "\n",
    "def max_pooling(x,strides,ksize,padding):\n",
    "  return tf.nn.max_pool(x, ksize=ksize,strides=strides, padding=padding)\n",
    "\n",
    "def generate_network(weight_variables,\\\n",
    "                      bias_variables,\\\n",
    "                      relu_layers,\\\n",
    "                      pooling_layers,\\\n",
    "                      fully_connected_layers,\\\n",
    "                      inputs,\\\n",
    "                      conv_strides,\\\n",
    "                      pool_stries,\\\n",
    "                      ksize,\\\n",
    "                      output_channels,\\\n",
    "                      conv_field_sizes,\\\n",
    "                      conv_field_depths,\\\n",
    "                      sd_weights\\\n",
    "                      ,bias_mean,\\\n",
    "                      padding,\\\n",
    "                      conv_layers,\\\n",
    "                      fc_layers,\\\n",
    "                      fc_shape,\\\n",
    "                      keep_prob,\\\n",
    "                      class_num,\\\n",
    "                      dropouts):\n",
    "    \n",
    "    # add convolutional layers\n",
    "    for k in range(conv_layers):\n",
    "        weight_variables.append(weight_variable([conv_field_sizes[k], conv_field_sizes[k], conv_field_depths[k],\\\n",
    "                                                 output_channels[k]],sd_weights))\n",
    "        bias_variables.append(bias_variable([output_channels[k]],bias_mean))\n",
    "        relu_layers.append(tf.nn.relu(two_dimensional_convolutional_layer(inputs[k],weight_variables[k],\\\n",
    "                                                                          conv_strides,padding) + bias_variables[k]))\n",
    "        pooling_layers.append(max_pooling(relu_layers[k],pool_strides,ksize,padding))\n",
    "        inputs.append(pooling_layers[k])\n",
    "        \n",
    "    # finally, add fully connected layers at end with dropout\n",
    "    for r in range(fc_layers):\n",
    "        weight_variables.append(weight_variable(fc_shape,sd_weights))\n",
    "        bias_variables.append(bias_variable([fc_shape[1]],bias_mean))\n",
    "        pooling_layers.append(tf.reshape(pooling_layers[-1],[-1,fc_shape[0]]))\n",
    "        fully_connected_layers.append(tf.nn.relu(tf.matmul(pooling_layers[-1], weight_variables[-1]) + bias_variables[-1]))\n",
    "        dropouts.append(tf.nn.dropout(fully_connected_layers[-1], keep_prob))\n",
    "    \n",
    "    # output layer\n",
    "    weight_variables.append(weight_variable([fc_shape[1],class_num],sd_weights))\n",
    "    bias_variables.append(bias_variable([class_num],bias_mean))\n",
    "    return tf.nn.softmax(tf.matmul(dropouts[-1],weight_variables[-1])+bias_variables[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", shape=[None, 784])\n",
    "observed = tf.placeholder(\"float\", shape=[None, 10])\n",
    "images = tf.reshape(X, [-1,28,28,1])\n",
    "\n",
    "# shape variables\n",
    "sd_weights = 0.1\n",
    "bias_mean = 0.1\n",
    "padding = 'SAME'\n",
    "conv_strides = [1,1,1,1]\n",
    "pool_strides = [1,2,2,1]\n",
    "ksize = [1,2,2,1]\n",
    "output_channels = [32,64]\n",
    "conv_field_sizes = [5,5]\n",
    "conv_field_depths = [1,32]\n",
    "fc_shape = [7*7*64,1024]\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "class_num = 10\n",
    "conv_layers = 2\n",
    "fc_layers = 1\n",
    "\n",
    "# layers variables\n",
    "weight_variables = []\n",
    "bias_variables = []\n",
    "relu_layers = []\n",
    "pooling_layers = []\n",
    "inputs = [images]\n",
    "fully_connected_layers = []\n",
    "dropouts = []\n",
    "\n",
    "prediction = generate_network(weight_variables,\\\n",
    "                      bias_variables,\\\n",
    "                      relu_layers,\\\n",
    "                      pooling_layers,\\\n",
    "                      fully_connected_layers,\\\n",
    "                      inputs,\\\n",
    "                      conv_strides,\\\n",
    "                      pool_strides,\\\n",
    "                      ksize,\\\n",
    "                      output_channels,\\\n",
    "                      conv_field_sizes,\\\n",
    "                      conv_field_depths,\\\n",
    "                      sd_weights\\\n",
    "                      ,bias_mean,\\\n",
    "                      padding,\\\n",
    "                      conv_layers,\\\n",
    "                      fc_layers,\\\n",
    "                      fc_shape,\\\n",
    "                      keep_prob,\\\n",
    "                      class_num,\\\n",
    "                      dropouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.04\n",
      "step 100, training accuracy 0.06\n",
      "step 200, training accuracy 0.1\n",
      "step 300, training accuracy 0.16\n",
      "step 400, training accuracy 0.16\n",
      "step 500, training accuracy 0.1\n",
      "step 600, training accuracy 0.1\n",
      "step 700, training accuracy 0.12\n",
      "step 800, training accuracy 0.16\n",
      "step 900, training accuracy 0.06\n",
      "step 1000, training accuracy 0.14\n",
      "step 1100, training accuracy 0.06\n",
      "step 1200, training accuracy 0.14\n",
      "step 1300, training accuracy 0.1\n",
      "step 1400, training accuracy 0.08\n",
      "step 1500, training accuracy 0.18\n",
      "step 1600, training accuracy 0.1\n",
      "step 1700, training accuracy 0.18\n",
      "step 1800, training accuracy 0.06\n",
      "step 1900, training accuracy 0.08\n",
      "step 2000, training accuracy 0.16\n",
      "step 2100, training accuracy 0.24\n",
      "step 2200, training accuracy 0.1\n",
      "step 2300, training accuracy 0.18\n",
      "step 2400, training accuracy 0.12\n",
      "step 2500, training accuracy 0.06\n",
      "step 2600, training accuracy 0.1\n",
      "step 2700, training accuracy 0.08\n",
      "step 2800, training accuracy 0.18\n",
      "step 2900, training accuracy 0.1\n",
      "step 3000, training accuracy 0.04\n",
      "step 3100, training accuracy 0.1\n",
      "step 3200, training accuracy 0.12\n",
      "step 3300, training accuracy 0\n",
      "step 3400, training accuracy 0.18\n",
      "step 3500, training accuracy 0.12\n",
      "step 3600, training accuracy 0.08\n",
      "step 3700, training accuracy 0.18\n",
      "step 3800, training accuracy 0.1\n",
      "step 3900, training accuracy 0.06\n",
      "step 4000, training accuracy 0.02\n",
      "step 4100, training accuracy 0.14\n",
      "step 4200, training accuracy 0.2\n",
      "step 4300, training accuracy 0.16\n",
      "step 4400, training accuracy 0.06\n",
      "step 4500, training accuracy 0.14\n",
      "step 4600, training accuracy 0.06\n",
      "step 4700, training accuracy 0.12\n",
      "step 4800, training accuracy 0.14\n",
      "step 4900, training accuracy 0.16\n",
      "step 5000, training accuracy 0.06\n",
      "step 5100, training accuracy 0.08\n",
      "step 5200, training accuracy 0.12\n",
      "step 5300, training accuracy 0.18\n",
      "step 5400, training accuracy 0.12\n",
      "step 5500, training accuracy 0.22\n",
      "step 5600, training accuracy 0.1\n",
      "step 5700, training accuracy 0.12\n",
      "step 5800, training accuracy 0.02\n",
      "step 5900, training accuracy 0.12\n",
      "step 6000, training accuracy 0.14\n",
      "step 6100, training accuracy 0.18\n",
      "step 6200, training accuracy 0.18\n",
      "step 6300, training accuracy 0.12\n",
      "step 6400, training accuracy 0.14\n",
      "step 6500, training accuracy 0.02\n",
      "step 6600, training accuracy 0.14\n",
      "step 6700, training accuracy 0.12\n",
      "step 6800, training accuracy 0.22\n",
      "step 6900, training accuracy 0.14\n",
      "step 7000, training accuracy 0.12\n",
      "step 7100, training accuracy 0.12\n",
      "step 7200, training accuracy 0.12\n",
      "step 7300, training accuracy 0.12\n",
      "step 7400, training accuracy 0.06\n",
      "step 7500, training accuracy 0.16\n",
      "step 7600, training accuracy 0.16\n",
      "step 7700, training accuracy 0.04\n",
      "step 7800, training accuracy 0.08\n",
      "step 7900, training accuracy 0.22\n",
      "step 8000, training accuracy 0.06\n",
      "step 8100, training accuracy 0.14\n",
      "step 8200, training accuracy 0.08\n",
      "step 8300, training accuracy 0.14\n",
      "step 8400, training accuracy 0.08\n",
      "step 8500, training accuracy 0.06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f49c98fd3132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         X: batch[0], observed: batch[1], keep_prob: 1.0})\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step %d, training accuracy %g\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \"\"\"\n\u001b[0;32m-> 1339\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   2959\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 2961\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 433\u001b[0;31m                                target_list)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_session = tf.InteractiveSession()\n",
    "squared_error = tf.reduce_sum(tf.pow(tf.reduce_sum(tf.sub(observed,prediction)),[2]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(squared_error)\n",
    "correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(observed,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "my_session.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%1000 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        X: batch[0], observed: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={X: batch[0], observed: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    X: mnist.test.images, observed: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
